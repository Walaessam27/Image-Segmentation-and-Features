# -*- coding: utf-8 -*-
"""ولاء عصام - Computer Vision Bootcamp Assignment 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ACLwjPPrNomeeqUeOWy553OQ4_Fp75yn

# Computer Vision Bootcamp: Assignment 2

## Reading

*Take* a photo of any object in your room using your mobile or laptop's camera

Upload the image into Colab. Then read the image
"""

# Import the needed libraries
import cv2
import matplotlib.pyplot as plt
import numpy as np
import time

# read the image
I = cv2.imread('2.jpg')

"""Resize the image to 512*512 pixels using the resize function in OpenCV"""

# Resize the image
resized_image = cv2.resize(I, (512,512))

"""## Converting"""

# Convert the reseized image to RGB
rgb_image = cv2.cvtColor(resized_image,cv2.COLOR_BGR2RGB)

# Convert the reseized image to grayscale
gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)

# show the rgb and Gray images image
plt.figure(figsize = (10,5))
plt.subplot(1,2,1)
plt.imshow(rgb_image)
plt.title('Origional image')
plt.subplot(1,2,2)
plt.imshow(gray_image, cmap = 'gray')
plt.title('Gray image')
plt.show

"""## Edge Detection

### Laplacian of Gaussian
"""

# Convolve the gray resized image with a Laplacian
m_l = np.array([[-1,-1,-1],
                [-1, 8,-1],
                [-1,-1,-1]])
edge_l = cv2.filter2D(gray_image, -1 , m_l)

# Convolve the gray resized image with a Gaussian of sigma 5
g_blur = cv2.GaussianBlur(gray_image, (33, 33), 5)

# Find the Laplacian of Gaussian
l_gaussian = cv2.filter2D(g_blur, -1 , m_l)

# Show the origional image, the laplacian, the gaussian, and the Laplacian of Gaussian results in one figure
plt.figure(figsize=(20,5))
plt.subplot(1,4,1)
plt.imshow(rgb_image)
plt.title('Origional image')
plt.subplot(1,4,2)
plt.imshow(edge_l, cmap = 'gray')
plt.title('Laplacian image')
plt.subplot(1,4,3)
plt.imshow(g_blur, cmap = 'gray')
plt.title('Gaussian image')
plt.subplot(1,4,4)
plt.imshow(l_gaussian, cmap = 'gray')
plt.title('Laplacian of Gaussian image')
plt.show

"""### Difference of Gaussians"""

# Convolve the gray resized image with two gaussians (one with a scale of 1 and another with a scale of 3)
g_blur1 = cv2.GaussianBlur(gray_image, (31, 31), 1)
g_blur2 = cv2.GaussianBlur(gray_image, (31, 31), 3)

# find the difference of gaussians
d_gaussian = g_blur2 - g_blur1

# Show the origional image, the two gaussians results, and the DoG results
plt.figure(figsize=(20,5))
plt.subplot(1,4,1)
plt.imshow(rgb_image)
plt.title('Origional image')
plt.subplot(1,4,2)
plt.imshow(g_blur1, cmap = 'gray')
plt.title('Gaussian1 image')
plt.subplot(1,4,3)
plt.imshow(g_blur2, cmap = 'gray')
plt.title('Gaussian2 image')
plt.subplot(1,4,4)
plt.imshow(d_gaussian, cmap = 'gray')
plt.title('Difference of Gaussian image')
plt.show

"""### Canny Edge Detector"""

# Find the median then the two thresholds of the gray resized image, and print the three values
med_val = np.median(gray_image)
lower = int(0.68 * med_val)
upper = int(1.32 * med_val)

# Apply automatic Canny edge detection using the computed thresholds
canny = cv2.Canny(gray_image, lower, upper)

# show the origional image, the LoG, the DoG, and the Canny results in one figure
plt.figure(figsize=(20,5))
plt.subplot(1,4,1)
plt.imshow(rgb_image)
plt.title('Origional image')
plt.subplot(1,4,2)
plt.imshow(l_gaussian, cmap = 'gray')
plt.title('Laplacian of Gaussian image')
plt.subplot(1,4,3)
plt.imshow(d_gaussian, cmap = 'gray')
plt.title('Difference of Gaussian image')
plt.subplot(1,4,4)
plt.imshow(canny, cmap = 'gray')
plt.title('Canny Edge Detector')
plt.show

"""## Morphological Operations

### Opening or Closing
"""

# enhance the DoG results using opening or closing, create a mask with suitable size and shape then use opening or closing
kernel = np.ones((4,4), np.uint8)
enhanced_dog = cv2.morphologyEx(d_gaussian, cv2.MORPH_OPEN, kernel)

# show the origional Dog and the enhanced DoG
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(d_gaussian, cmap='gray')
plt.title('Original DoG')
plt.subplot(1, 2, 2)
plt.imshow(enhanced_dog, cmap='gray')
plt.title('Enhanced DoG (Opening)')
plt.show()

"""### Histogram and Binarization"""

# Find the histogram of the gray resized image and plot it
histo = cv2.calcHist([gray_image], [0], None, [256], [0, 255] )
plt.plot(histo)
plt.show

# Calculate the histogram for each color channel and show them in one plot
colors = ['r', 'g', 'b']
for i , color in enumerate(colors):
  histo = cv2.calcHist([rgb_image], [i], None, [256], [0, 255])
  plt.plot(histo, color = color)
plt.show()

# Using the peak of the histogram or the median value, binarise the gray scale image and show it
theshold = 120
binary_median = np.where(gray_image > theshold, 255, 0)
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(gray_image, cmap='gray')
plt.title('Gray image')
plt.subplot(1, 2, 2)
plt.imshow(binary_median, cmap='gray')
plt.title('Binary image')
plt.show

"""## Color Segmentation"""

# Load the image attached to the assignment called "segment"
I_s = cv2.imread('segment.jpg')
resized_image_s = cv2.resize(I_s, (512,512))
rgb_image_s = cv2.cvtColor(resized_image_s,cv2.COLOR_BGR2RGB)
gray_image_s = cv2.cvtColor(resized_image_s, cv2.COLOR_BGR2GRAY)

# Convert to suitable color space
hsv_image_s = cv2.cvtColor(resized_image_s, cv2.COLOR_BGR2HSV)

# Define the color range for segmentation, we want to extract the object. Hint: you can extract the green then inverse the mask
lower_color = np.array([35, 50, 50])
upper_color = np.array([85, 255, 255])

# Create a mask with the specified color range
mask = cv2.inRange(hsv_image_s, lower_color, upper_color)
inverse_mask = cv2.bitwise_not(mask)

# enhance the mask using morphological operations
kernel = np.ones((5, 5), np.uint8)
mask_open = cv2.morphologyEx(inverse_mask, cv2.MORPH_OPEN, kernel)
mask_finalenhanced = cv2.morphologyEx(mask_open, cv2.MORPH_CLOSE, kernel)

# apply the mask on the original RGB image
segment_image = cv2.bitwise_and(rgb_image_s, rgb_image_s, mask= mask_finalenhanced)

# Display the original and segmented images
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(rgb_image_s)
plt.title('Original Image')
plt.subplot(1, 2, 2)
plt.imshow(segment_image)
plt.title('Segmented Image')
plt.show()

"""## Feature extraction

### Harris
"""

# Load the image attached to the assignment called "extract"
I_e = cv2.imread('extract.jpg')
resized_image_e = cv2.resize(I_e, (512,512))
rgb_image_e = cv2.cvtColor(resized_image_e,cv2.COLOR_BGR2RGB)
gray_image_e = cv2.cvtColor(resized_image_e, cv2.COLOR_BGR2GRAY)

# convert it to suitable color space and value type for Harries function
gray_image_float = np.float32(gray_image_e)

# Apply Harris function, and print its execution time
start_time = time.time()
harris_corners = cv2.cornerHarris(gray_image_float, 2, 3, 0.04)
execution_time = time.time() - start_time
print(f"Execution time= {execution_time} seconds")

threshold = 0.01*harris_corners.max()
corner_image = rgb_image_e.copy()
for y in range(0, harris_corners.shape[0]):
    for x in range(0, harris_corners.shape[1]):
        if harris_corners[y, x] > threshold:
            cv2.circle(corner_image, (x, y), 5, (255, 0, 0), -1)

# filter the number of corners and show them in red on the origional RGB image
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(rgb_image_e)
plt.title('Original image')
plt.subplot(1, 2, 2)
plt.imshow(corner_image)
plt.title('Corners in image')
plt.show()

"""### SIFT"""

# convert it to suitable color space and value type for SIFT function
sift = cv2.SIFT_create()

# Apply SIFT function, and print its execution time and number of keypoints
start_time = time.time()
keypoints, descriptors = sift.detectAndCompute(gray_image_e, None)
execution_time = time.time() - start_time  # End timing
print(f"Execution time= {execution_time} seconds")
print(f"Number of keypoints= {len(keypoints)}")
keypoint_image = cv2.drawKeypoints(rgb_image_e, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

# show the keypoints on the origional RGB image
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(rgb_image_e)
plt.title('Original image')
plt.subplot(1, 2, 2)
plt.imshow(keypoint_image)
plt.title('SIFT Keypoints')
plt.show()

"""### Fast"""

# convert it to suitable color space and value type for Fast function
fast = cv2.FastFeatureDetector_create()

# Apply Fast function, and print its execution time and number of keypoints
start_time = time.time()
keypoints = fast.detect(gray_image_e, None)
execution_time = time.time() - start_time
print(f"Execution time= {execution_time} seconds")
print(f"Number of keypoints= {len(keypoints)}")
keypoint_image = cv2.drawKeypoints(rgb_image_e, keypoints, None, color=(255, 0, 0))

# show the keypoints on the origional RGB image
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(rgb_image_e)
plt.title('Original image')
plt.subplot(1, 2, 2)
plt.imshow(keypoint_image)
plt.title('FAST Keypoints')
plt.show()

"""## What real life problems can you solve using the methods applied in this assignment?

Your Answer Here: It is important for 3D reconstruction, robotics navigation, and image matching. They enable machines to recognize and match key points in images, and aligning images for panoramic views or medical analysis.
"""